<html><head>
<base href="https://naxingyu.github.io" />
<title>Xingyu Na</title>
</head>

<style>
</style>

<body marginwidth="0" marginheight="0" bgcolor="#FFFFFF" text="#000000" link="#0000C8" alink="C80000">
<table border="0" cellspacing="15" cellpadding="0" width="1000">
<td class="sidebar">&nbsp;</td>

<td class="sidebar" valign="top">
<table border="0" cellspacing="0" cellpadding="2">
&nbsp;&nbsp;&nbsp;&nbsp;
</table>
</td>

<td valign="top">
<p></p>
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<td align="left" width="60%">
<font face="helvetica, ariel, 'sans serif'" size="3"> 
    <font size="+2">
    <b>Xingyu Na</b><br></font>
</font>
<font face="helvetica, ariel, 'sans serif'">
    <br>
    Senior Applied Scientist, <a href="http://www.microsoft.com">Microsoft</a><br>
    Mailing Address: 5 DanLing Street, Beijing, China<br>
    Office: 11354, Microsoft China Tower 2<br>
    Email: asr.naxingyu -at- gmail.com<br>
    <p></p>
    <p></p>
</font>
</td>
<td valign="top" align="left">
<img src="https://avatars3.githubusercontent.com/u/3320260?v=3&s=400" height="200">
</td>
</table>

<p>
<hr size="1" align="left" noshade></p>
<p>
I received my Ph.D. degree from <a href="http://www.bit.edu.cn">Beijing Institute of Technology</a> in 2014
under supervision of Prof. Jingming Kuang and Prof. Xiang Xie. I was a visiting Ph.D. student in
<a href="http://people.idiap.ch/pgarner">Dr. Philip N. Garner</a>'s group at <a href="http://www.idiap.ch">Idiap Research Institute</a>
in 2012 and 2013.
<br clear="left"></p>

<h2>News</h2>
<ul>
<li>18/09/2017: Our paper "AIShell-1: An Open-Source Mandarin Speech Corpus and A Speech Recognition Baseline" is accepted by Oriental COCOSDA 2017 as an oral presentation!</li>
<li>21/08/2017: I'm joining Microsoft China!</li>
<li><strike>02/12/2016: I'm joining Alibaba Robotics Corp. as a Senior Staff Engineer!</strike></li>
<li>05/09/2016: Attending Interspeech 2016 at San Francisco!</li>
<li><strike>10/12/2015: I'm joining Letv as a Senior Researcher on speech recognition</strike>.</li>
<li>19/03/2015: Our paper "Incremental Syllable-Context Phonetic Vocoding" was accepted by TASLP.</li>
<li>14/07/2014: I gave a talk about "Real-Time Speech Synthesis" at IEEE ICME 2014.</li>
<li><strike>07/03/2014: I'm joining Chinese Academy of Sciences, Institute of Acoustics as an Assistant Researcher</strike>.</li>
</ul>

<h2>Projects</h2>
<ul>
<strong>Playing with <a href="http://kaldi-asr.org">Kaldi</a></strong> (the most popular open-source speech recognition toolkit)</br>
My <a href="https://github.com/kaldi-asr/kaldi/commits?author=naxingyu">contributions</a> are<br>
<ul>
<li>created components for convolutional neural network in nnet2</li>
<li>created and tuned left-biphone setups for Chain model</li>
<li>modified transition model and HMM topology kernel</li>
<li>maintainer of aishell, fisher_swbd, hkust, gale_mandarin and thchs30 benchmarks</li>
</ul>
<strong>Playing with <a href="http://hts.sp.nitech.ac.jp/">HTS</a></strong> (the most popular open-source speech synthesis toolkit)<br>
I used HTS a lot for my PhD thesis. I shared the tools that were useful to me on Github and
some of them are included as HTS <a href="http://hts.sp.nitech.ac.jp/?Extensions">extentions</a><br>
<ul>
<li><a href="https://github.com/naxingyu/HTS_PDFparser">HTS_PDFparser</a>: a lite parser for hts_engine model</li>
<li><a href="https://github.com/naxingyu/StreamGenerator">StreamGenerator</a>: a single stream speech parameter generator for customizable hts_engine</li>
<li><a href="https://github.com/naxingyu/MGEtraining">MGETraining</a>: HTS training scripts supporting minimum-generation-error training</li>
</ul>
<strong>Voxforge for Chinese</strong>
Calling for voluntary participants!<br>
</ul>
<br>

<h2>Publications</h2>
<ul>
<strong>AISHELL-2: Transforming Mandarin ASR Research Into Industrial Scale</strong><br>
Jiayu Du, Xingyu Na, Xuechen Liu, Hui Bu<br>
<em>arXiv</em>, 1808.10583, 2018
<a href="https://arxiv.org/abs/1808.10583">[paper]</a>
<a href="https://github.com/kaldi-asr/kaldi/tree/master/egs/aishell2">[Kaldi recipe]</a>
<br>
<br>
<strong>AISHELL-1: An Open-Source Mandarin Speech Corpus and A Speech Recognition Baseline</strong><br>
Hui Bu, Jiayu Du, Xingyu Na, Bengu Wu, Hao Zheng<br>
<em>O-COCOSDA</em>, Seoul, R. O. Korea, 2017
<a href="https://ieeexplore.ieee.org/document/8384449">[paper]</a>
<a href="https://github.com/kaldi-asr/kaldi/blob/master/egs/aishell/s5">[Kaldi recipe]</a>
<br>
<br>
<strong>Purely Sequence-trained Neural Networks for ASR based on Lattice-free MMI</strong><br>
Daniel Povey, Vijayaditya Peddinti, Daniel Galvez, Pegah Ghahrmani, Vimal Manohar, Xingyu Na, Yiming Wang, Sanjeev Khudanpur<br>
<em>Interspeech</em>, San Francisco, US, 2016
<a href="http://isca-speech.org/archive/Interspeech_2016/pdfs/0595.PDF">[paper]</a>
<a href="https://github.com/kaldi-asr/kaldi/blob/master/egs/fisher_swbd/s5/local/chain/run_tdnn_7b.sh">[Kaldi recipe]</a>
<br>
<br>
<strong>An Emperical Exploration of CTC Acoustic Models</strong><br>
Yajie Miao, Mohammad Gowayyed,  Xingyu Na, Tom Ko, Florian Metze, Alexander Waibel<br>
<em>IEEE Conference on Acoustic, Speech and Signal Processing</em>, Shanghai, China, 2016
<a href="http://ieeexplore.ieee.org/document/7472152">[paper]</a>
<a href="https://github.com/srvk/eesen/tree/master/asr_egs/hkust/v1">[Eesen recipe]</a>
<br>
<br>
<strong>Two-stage ASGD Framework for Parallel Training of DNN Acoustic Models using Ethernet</strong><br>
Zhichao Wang, Xingyu Na, Yonghong Yan<br>
<em>IEEE Automatic Speech Recognition and Understanding Workshop</em>, Arizona, US, 2015
<a href="http://ieeexplore.ieee.org/document/7404774">[paper]</a>
<br>
<br>
<strong>Incremental Syllable-Context Phonetic Vocoding</strong><br>
Milos Cernak, Phil Garner, Alexandros Lazaridis, Petr Motlicek, Xingyu Na<br>
<em>IEEE/ACM Transactions on Acoustic, Speech and Language Processing</em>, 23(6), 2015
<a href="http://ieeexplore.ieee.org/document/7073585">[paper]</a>
<a href="http://www.idiap.ch/project/recod">[project]</a>
<br>
<br>
<strong>Syllabic Pitch Tuning for Neutral-to-Emotional Voice Conversion</strong><br>
Lakshmi Saheer, Xingyu Na, Milos Cernak<br>
<em>Idiap Research Report</em>, Martigny, Switzerland, 2015
<a href="http://publications.idiap.ch/downloads/reports/2015/Saheer_Idiap-RR-31-2015.pdf">[paper]</a>
<br>
<br>
<strong>Low-Latency Parameter Generation for Real-time Embedded Speech Synthesis System</strong><br>
Xingyu Na, Xiang Xie, Jingming Kuang<br>
<em>IEEE International Conference on Multimedia And Expo</em>, Chengdu, China, 2014
<a href="http://ieeexplore.ieee.org/document/6890197">[paper]</a>
<br>
<br>
<strong>Improving Voice Quality of HMM-based Speech Synthesis Using Voice Conversion Method</strong><br>
Yishan Jiao, Xiang Xie, Xingyu Na, Ming Tu<br>
<em>IEEE Conference on Acoustic, Speech and Signal Processing</em>, Florence, Italy, 2014
<a href="http://ieeexplore.ieee.org/document/6855141">[paper]</a>
<br>
<br>
<strong>Syllable-based Pitch Encoding for Low Bit Rate Speech Coding with Recognition/Synthesis Architecture</strong><br>
Milos Cernak, Xingyu Na, Phil Garner<br>
<em>Interspeech</em>, Lyon, France, 2013
<a href="http://isca-speech.org/archive/archive_papers/interspeech_2013/i13_3449.pdf">[paper]</a>
<br>
<br>
<strong>Convolutional Pitch Target Approximation Model for Speech Synthesis</strong><br>
Xingyu Na, Phil Garner<br>
<em>Idiap Research Report</em>, Martigny, Switzerland, 2013
<a href="http://publications.idiap.ch/downloads/reports/2013/Na_Idiap-RR-05-2013.pdf">[paper]</a>
<br>
<br>
<strong>An Improved Tone Labeling and Prediction Method with Non-uniform Segmentation of F0 Contour</strong><br>
Xingyu Na, Xiang Xie, Jingming Kuang, Yaling He<br>
<em>IEEE International Symposium on Chinese Spoken Language Processing</em>, Hongkong, China, 2012
<a href="http://ieeexplore.ieee.org/document/6423467">[paper]</a>
<br>
<br>
<strong>Tone Generation by Maximizing Joint Likelihood of Syllabic HMMs for Mandarin Speech Synthesis</strong><br>
Xingyu Na, Chaomin Wang, Xiang Xie, Jingming Kuang, Yaling He<br>
<em>Speech Prosody</em>, Shanghai, China, 2012
<a href="http://isca-speech.org/archive/sp2012/papers/sp12_023.pdf">[paper]</a>
<br>
<br>
</ul>

<h2>Professional Activities</h2>
<ul>
  <li>Reviewer:</li>
  <ul>
    <li>Speech Communication</li>
    <li>EURASIP Journal on Audio, Speech, and Music Processing</li>
    <li>KSII Transactions on Internet and Information Systems</li>
    <li>IEEE Signal Processing Letters</li>
    <li>Journal of the Audio Engineering Society</li>
  </ul>
</ul>

<p><a href="http://s04.flagcounter.com/more/NF8T"><img src="http://s04.flagcounter.com/count/NF8T/bg_FFFFFF/txt_000000/border_CCCCCC/columns_4/maxflags_20/viewers_0/labels_1/pageviews_1/flags_0/" alt="Free counters!" border="0"></a></p>
</td>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-112817246-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-112817246-1');
</script>
</table>
</body>
</html>
